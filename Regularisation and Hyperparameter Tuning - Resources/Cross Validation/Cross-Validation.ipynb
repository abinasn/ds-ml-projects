{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb15be5f-0ce5-49c2-818d-bed8697248b2",
   "metadata": {},
   "source": [
    "## Cross-Validation\n",
    "\n",
    "**Cross-validation**, a technique where the dataset is split into multiple folds for repeated training and testing, helps assess model performance more reliably. We will demonstrate how it is particularly valuable when working with limited data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d04ff36-e964-472e-ac20-5666b96b1304",
   "metadata": {},
   "source": [
    "Importing necessary libraries and in-built dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b80a9380-d84f-4750-a1ae-c769ce846406",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes  # Diabetes dataset\n",
    "from sklearn.linear_model import LinearRegression  # Linear regression model\n",
    "from sklearn.model_selection import train_test_split, cross_val_score  # Train-test split and cross-validation\n",
    "from sklearn.metrics import mean_squared_error  # MSE\n",
    "import numpy as np; import pandas as pd  # For data processing\n",
    "import warnings; warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95165bf2-13a6-4cf6-910a-4c72be930e58",
   "metadata": {},
   "source": [
    "For the purposes of this demonstration, we will select a sample of only 100 rows of our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3cce43f-d9b5-44e1-bcb3-d830c1d8bb30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068332</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031988</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         s4        s5        s6  target  \n",
       "0 -0.002592  0.019907 -0.017646   151.0  \n",
       "1 -0.039493 -0.068332 -0.092204    75.0  \n",
       "2 -0.002592  0.002861 -0.025930   141.0  \n",
       "3  0.034309  0.022688 -0.009362   206.0  \n",
       "4 -0.002592 -0.031988 -0.046641   135.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_full = load_diabetes()\n",
    "df = pd.DataFrame(data_full.data, columns = data_full.feature_names)\n",
    "df['target'] = data_full.target\n",
    "\n",
    "data = df.sample(n = 100, random_state = 42)  # Randomly sample 100 rows\n",
    "\n",
    "# Split into X and y\n",
    "X = data[data_full.feature_names]\n",
    "y = data['target']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaeec10-0a38-42cf-b0c3-5fa9502c2a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dimensions of X:', X.shape); print('Dimensions of y:', y.shape)  # Checking the number of records and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46899606-6239-4057-abcf-f4444a3dfd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T  # Verifying that the predictors are on the same scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bf7826-2a1a-48eb-8078-105729926605",
   "metadata": {},
   "source": [
    "### Linear Regression with Train-Test Split\n",
    "\n",
    "Let's split our model using a basic train-test split, i.e., **hold-out validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ead4b5-15c9-4c50-9e98-f7feade15953",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "print('Dimensions of X_train:', X_train.shape); print('Dimensions of y_train:', y_train.shape)\n",
    "print('Dimensions of X_test:', X_test.shape); print('Dimensions of y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6920848-b55c-44f8-a590-dc2da444bcf5",
   "metadata": {},
   "source": [
    "Let's now fit this data to a linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4973f8dd-a60b-4d4b-8d86-2c54c0ecc772",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)  # Fitting linear regression model on training data\n",
    "\n",
    "y_pred_train = lr_model.predict(X_train); y_pred_test = lr_model.predict(X_test)  # Training and testing predictions\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_pred_train); mse_test = mean_squared_error(y_test, y_pred_test)  # Training and testing MSEs\n",
    "\n",
    "print('Training MSE =', np.round(mse_train, 2)); print('Testing MSE =', np.round(mse_test, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd191119-adf0-4698-b8c2-1a9fccbc05dd",
   "metadata": {},
   "source": [
    "We can see that our model has overfit on the training data, as the MSE for testing predictions is far larger than for the training ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd22ddd-8e4a-4ef2-94b1-c5f8db85c616",
   "metadata": {},
   "source": [
    "### Linear Regression with Cross-Validation\n",
    "\n",
    "Now, we will use cross-validation, dividing the data into five folds (each with an 80:20 train:test split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a55a63f-f880-4937-8fbe-06441cac9248",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LinearRegression()\n",
    "cv_scores = cross_val_score(lr_model, X, y, cv = 5, scoring = 'neg_mean_squared_error')  # No need to use split data\n",
    "print('Cross-validation MSE scores:', np.abs(np.round(cv_scores, 2))); print('Mean cross-validation MSE score:', np.abs(np.round(np.mean(cv_scores), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268186d9-7265-4961-a084-de9399c7b22c",
   "metadata": {},
   "source": [
    "Our cross-validation MSE score is far closer to the training MSE than with just the train-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cee1478-6f44-431a-9dc7-aa8d6330acaa",
   "metadata": {},
   "source": [
    "### Linear Regression with Cross-Validation and Train-Test Split\n",
    "\n",
    "Ideally, in a machine learning pipeline, we want to typically incorporate both cross-validation as well as testing\n",
    "\n",
    "We will split the data into training and testing and then set aside the testing data entirely; this will serve as \"unseen\" data for our cross-validated model. The model will be cross-validated on various folds of only the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84058c24-3379-4547-aa2e-0797e41ffb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LinearRegression()\n",
    "cv_scores = cross_val_score(lr_model, X_train, y_train, cv = 5, scoring = 'neg_mean_squared_error')  # Use training data for cross-validation\n",
    "print('Cross-validation MSE scores:', np.abs(np.round(cv_scores, 2))); print('Mean MSE score:', np.abs(np.round(np.mean(cv_scores), 2)))\n",
    "lr_model.fit(X_train, y_train)  # Train on the training data\n",
    "y_pred_test = lr_model.predict(X_test); mse_test = mean_squared_error(y_test, y_pred_test)  # Testing performance\n",
    "print('Testing MSE =', np.round(mse_test, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1857aff7-e3d0-4b3f-8d4d-44dfc500a117",
   "metadata": {},
   "source": [
    "In spite of the training set now containing only 80% of the total data, it still generalises better to \"unseen\" data than the model without cross-validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
